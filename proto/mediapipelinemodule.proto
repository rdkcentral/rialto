/*
 * If not stated otherwise in this file or this component's LICENSE file the
 * following copyright and licenses apply:
 *
 * Copyright 2022 Sky UK
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto2";

import "google/protobuf/descriptor.proto";
import "rialtocommon.proto";

package firebolt.rialto;

// You need this to generate the rpc service stubs
option cc_generic_services = true;

/**
 * @fn int createSession(uint32 max_width, uint32 max_height)
 * @brief Creates a new A/V playback session.
 *
 * @param[in]  max_width    The maximum width of the video.
 * @param[in]  max_height   The maximum height of the video.
 *
 * A client can have multiple A/V sessions, although typically only one will be streaming at a time.  A session is used
 * to group a one or more video and audio media sources together into a single playback session.
 *
 * Sessions are unique to a single IPC connection to the server, it is not possible to use a session id created on
 * one IPC connection with another IPC connection.  When an IPC connection is closed the session ids are invalidated
 * and the resource allocated to the session on the server are freed.
 *
 * @returns a unique numeric session id value that should be used for all subsequent operations on the session.
 */
message CreateSessionRequest {
    optional uint32 max_width = 1;
    optional uint32 max_height = 2;
}
message CreateSessionResponse {
    optional int32 session_id = 1 [default = -1];
}

/**
 * @fn void destroySession(int session_id)
 * @brief Destroys an A/V playback session.
 *
 * @param[in]  session_id   The id of the session to destroy.
 *
 * Destroys an A/V playback session freeing all resources on the server.
 *
 */
message DestroySessionRequest {
  optional int32 session_id = 1 [default = -1];
}
message DestroySessionResponse {
}

/**
 * @fn void load(MediaType type, string mime_type, string url)
 * @brief Loads the media pipeline.
 *
 * @param[in]  session_id   The id of the A/V session.
 * @param[in]  type         The type of media.
 * @param[in]  mime_type    The mime type.
 * @param[in]  url          The url.
 *
 */
message LoadRequest {
    enum MediaType {
        UNKNOWN = 0;        ///< Media type not known.
        MSE = 1;            ///< Media is MSE and will request data.
    }

    optional int32      session_id = 1 [default = -1];
    optional MediaType  type = 2;
    optional string     mime_type = 3;
    optional string     url = 4;
}
message LoadResponse {
}

/**
 * @fn int attachSource(int session_id, MediaSourceType media_type, string caps)
 * @brief Attaches a new media source on a session with the given capabilities.
 *
 * @param[in]  session_id   The id of the A/V session.
 * @param[in]  media_type   The media source type.
 * @param[in]  caps         The capabilities of the source.
 *
 * A client will typically create a single audio and video media source on a given session.
 *
 * Media sources are unique to an A/V session, it is not possible to use a media source id created on one session with
 * another session.  When a session is destroyed the media source ids are invalidated and the resource allocated to the
 * media source on the server are freed.
 *
 * @returns a unique numeric media source id value that should be used for all subsequent operations on the media source.
 */
message AttachSourceRequest {
    enum SegmentAlignment {
        ALIGNMENT_UNDEFINED = 0;
        ALIGNMENT_NAL       = 1;
        ALIGNMENT_AU        = 2;
    }

    enum StreamFormat {
        STREAM_FORMAT_UNDEFINED   = 0;
        STREAM_FORMAT_RAW         = 1;
        STREAM_FORMAT_AVC         = 2;
        STREAM_FORMAT_BYTE_STREAM = 3;
        STREAM_FORMAT_HVC1        = 4;
        STREAM_FORMAT_HEV1        = 5;
    }

    enum ConfigType {
        CONFIG_TYPE_UNKNOWN            = 0;
        CONFIG_TYPE_AUDIO              = 1;
        CONFIG_TYPE_VIDEO              = 2;
        CONFIG_TYPE_VIDEO_DOLBY_VISION = 3;
        CONFIG_TYPE_SUBTITLE           = 4;
    }

    message AudioConfig {
        enum Format {
            S8 = 0;
            U8 = 1;
            S16LE = 2;
            S16BE = 3;
            U16LE = 4;
            U16BE = 5;
            S24_32LE = 6;
            S24_32BE = 7;
            U24_32LE = 8;
            U24_32BE = 9;
            S32LE = 10;
            S32BE = 11;
            U32LE = 12;
            U32BE = 13;
            S24LE = 14;
            S24BE = 15;
            U24LE = 16;
            U24BE = 17;
            S20LE = 18;
            S20BE = 19;
            U20LE = 20;
            U20BE = 21;
            S18LE = 22;
            S18BE = 23;
            U18LE = 24;
            U18BE = 25;
            F32LE = 26;
            F32BE = 27;
            F64LE = 28;
            F64BE = 29;
        }

        enum Layout {
            INTERLEAVED = 0;
            NON_INTERLEAVED = 1;
        }

        optional uint32 number_of_channels = 1;   ///< The number of channels.
        optional uint32 sample_rate = 2;         ///< The sampling rate.
        optional bytes codec_specific_config = 3; ///The audio specific config. Zero length if no specific config
        optional Format format = 4; ///< The Format of the audio samples.
        optional Layout layout = 5; ///< The layout of channels within a buffer.
        optional uint64 channel_mask = 6; ///< Bitmask of channel positions present.
    }

    message CodecData {
        enum Type {
            BUFFER = 1;
            STRING = 2;
        }
        optional bytes data = 1; /* Buffer containing updated codec data for video segments */
        optional Type type = 2;  /* Type of data */
    }

    optional int32 session_id = 1 [default = -1];
    optional ConfigType config_type = 2;
    optional string mime_type = 3;
    optional bool has_drm = 4;
    optional int32 width = 5;
    optional int32 height = 6;
    optional SegmentAlignment segment_alignment = 7; /* Segment alignment can be specified for H264/H265, will use NAL if not set */
    optional AudioConfig audio_config = 8;
    optional CodecData codec_data = 9;
    optional StreamFormat stream_format = 10;
    optional uint32 dolby_vision_profile = 11;
    optional string text_track_identifier = 12;

}
message AttachSourceResponse {
    optional int32 source_id = 1 [default = -1]; 
}

/**
 * @fn void removeSource(int session_id, int source_id)
 * @brief Remove a media source for a session.
 *
 * @param[in]  session_id   The id of the A/V session.
 * @param[in]  source_id  The id of the media source to destroy.
 *
 */
message RemoveSourceRequest {
  optional int32 session_id = 1 [default = -1];
  optional int32 source_id = 2 [default = -1];
}
message RemoveSourceResponse {
}

/**
 * @fn void allSourcesAttached(int session_id)
 * @brief Notify server that all sources were attached
 *
 * @param[in]  session_id   The id of the A/V session.
 *
 */
message AllSourcesAttachedRequest {
  optional int32 session_id = 1 [default = -1];
}
message AllSourcesAttachedResponse {
}

/**
 * @fn void setVideoWindow(int session_id, uint x, uint y, uint width, uint height)
 * @brief Sets the on-screen dimensions of the video window associated with the session
 *
 * @param session_id        The id of the A/V session the request is for.
 * @param x                 The x position in pixels.
 * @param y                 The y position in pixels.
 * @param width             The width in pixels.
 * @param height            The height in pixels.
 *
 */
message SetVideoWindowRequest {
    optional int32 session_id = 1 [default = -1];
    optional uint32 x = 2;
    optional uint32 y = 3;
    optional uint32 width = 4;
    optional uint32 height = 5;
}
message SetVideoWindowResponse {
}

/**
 * @fn void play(int session_id)
 * @brief Starts playback on a session.
 *
 * @param[in]  session_id   The id of the A/V session.
 *
 * This method is asynchronous. Once the backend is successfully playing it will notify the media player client of
 * playback state.
 *
 */
message PlayRequest {
    optional int32 session_id = 1 [default = -1];
}
message PlayResponse {
}

/**
 * @fn void pause(int session_id)
 * @brief Pauses the playback on a session.
 *
 * @param[in]  session_id   The id of the A/V session.
 *
 * This method is asynchronous. Once the backend is successfully pauseed it will notify the media player client of
 * playback state.
 *
 */
message PauseRequest {
    optional int32 session_id = 1 [default = -1];
}
message PauseResponse {
}

/**
 * @fn void stop(int session_id)
 * @brief Stops playback of the media.
 *
 * @param[in]  session_id   The id of the A/V session.
 *
 * This method is asynchronous. Once the backend has successfully stopped playback it will notify the media player
 * client of playback state.
 *
 */
message StopRequest {
    optional int32 session_id = 1 [default = -1];
}
message StopResponse {
}

/**
 * @fn void setPosition(int session_id, int64 position)
 * @brief Set the playback position in nanoseconds.
 *
 * @param[in]  session_id   The id of the A/V session.
 * @param[in]  position     The playback position in nanoseconds.
 *
 * If playback has not started this method sets the start position for playback. If playback has started this method
 * performs a seek.
 *
 * This method is asynchronous. For MSE playback Rialto Client will already be in the SEEKING state when this method is
 * called. This method is used to tell PLAYER that data for the new position will be supplied. When seeking has
 * completed and PLAYER is playing the new data the state SEEK_DONE is notified followed by PLAYING.
 *
 */
message SetPositionRequest {
    optional int32 session_id = 1 [default = -1];
    optional int64 position = 2 [default = -1];
}
message SetPositionResponse {
}

/**
 * @fn void getPosition(int session_id)
 * @brief Get the playback position in nanoseconds.
 *
 * @param[in]  session_id   The id of the A/V session.
 *
 * This method is considered to be sychronous, it returns current playback position
 *
 */
message GetPositionRequest {
    optional int32 session_id = 1 [default = -1];
}
message GetPositionResponse {
    optional int64 position = 1 [default = -1];
}

/**
 * @fn void setPlaybackRate(int session_id, double rate)
 * @brief Set the playback position in nanoseconds.
 *
 * @param[in]  session_id   The id of the A/V session.
 * @param[in]  rate         The playback rate to be set
 *
 * If playback has not started this method sets the playback rate. This method is asynchronous.
 *
 */
message SetPlaybackRateRequest {
    optional int32 session_id = 1 [default = -1];
    optional double rate = 2;
}
message SetPlaybackRateResponse {
}

/**
 * @fn void haveData(int session_id, MediaSourceStatus status, uint num_frames, uint request_id)
 * @brief Notify that the data is ready to be consumed in response to a NeedMediaDataEvent.
 *
 * @param session_id        The id of the A/V session the request is for.
 * @param status            The status of the media source
 * @param num_frames        The number of frames written to the shared memory.
 * @param request_id        The id of the request, this should match the value in the NeedMediaDataEvent event.
 */
message HaveDataRequest {
    enum MediaSourceStatus {
        UNKNOWN = 0;                ///< Unknown.
        OK = 1;                     ///< Source data provided without error.
        EOS = 2;                    ///< Source reached the end of stream.
        ERROR = 3;                  ///< There was an error providing source data.
        CODEC_CHANGED = 4;          ///< strThe codec has changed and the decoder must be reconfigured.
        NO_AVAILABLE_SAMPLES = 5;   ///< Could not retrieve media samples.
    };

    optional int32 session_id = 1 [default = -1];
    optional MediaSourceStatus status = 2;
    optional uint32 num_frames = 3;
    optional uint32 request_id = 4;
}
message HaveDataResponse {
}

/**
 * @fn void renderFrame(int session_id)
 * @brief Requests to render a prerolled frame
 *
 * @param session_id        The id of the A/V session the request is for.
 */
message RenderFrameRequest {
    optional int32 session_id = 1 [default = -1];
}
message RenderFrameResponse {
}

/**
 * @fn void setVolume(int session_id, double volume, uint32 volumeDuration, EaseType easeType)
 * @brief Set the volume level and transition duration with easing type
 *
 * @param[in] session_id  The id of the A/V session the request is for.
 * @param[in] volume : Target volume level (0.0 - 1.0)
 * @param[in] volume_duration : Duration of the volume transition in milliseconds
 * @param[in] ease_type : Easing type for the volume transition
 *
 */
message SetVolumeRequest {
    enum EaseType {
        EASE_LINEAR = 0;
        EASE_IN_CUBIC = 1;
        EASE_OUT_CUBIC = 2;
    };

    optional int32 session_id = 1 [default = -1];
    optional double volume = 2 [default = -1];
    optional uint32 volume_duration = 3;
    optional EaseType ease_type = 4;
}
message SetVolumeResponse {
}

/**
 * @fn void getVolume(double &volume)
 * @brief Get current audio level. Fetches the current volume level for the pipeline.
 *
 * @param[in]  session_id  The id of the A/V session the request is for.
 * @param[out] volume      Current volume level (range 0.0 - 1.0)
 *
 * @retval true on success false otherwise
 */
message GetVolumeRequest {
    optional int32 session_id = 1 [default = -1];
}
message GetVolumeResponse {
    optional double volume = 1 [default = -1];
}

/**
 * @fn void setMute(bool mute, int32_t source_id)
 * @brief Set mute status of pipeline.
 *
 * @param[in] session_id  The id of the A/V session the request is for.
 * @param[in] mute        Desired mute state, true=muted, false=not muted
*  @param[in] source_id   The media source ID.
 *
 */
message SetMuteRequest {
    optional int32 session_id = 1 [default = -1];
    optional bool mute = 2;
    optional int32 source_id = 3 [default = -1];
}
message SetMuteResponse {
}

/**
 * @fn void getMute(bool &mute)
 * @brief Get current mute status of the pipeline
 *
 * @param[in]  session_id  The id of the A/V session the request is for.
 * @param[out] mute      Current mute state
 *
 * @retval true on success false otherwise
 */
message GetMuteRequest {
    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
}
message GetMuteResponse {
    optional bool mute = 1;
}

/**
 * @fn void setTextTrackIdentifier(const std::string &textTrackIdentifier)
 * @brief Change Text Track Identifier
 *
 * @param[in] textTrackIdentifier Text track identifier of subtitle stream
 *
 * @retval true on success false otherwise
 *
 */
message SetTextTrackIdentifierRequest {
    optional int32 session_id = 1 [default = -1];
    optional string text_track_identifier = 2;
}
message SetTextTrackIdentifierResponse {
}

/**
 * @fn void getTextTrackIdentifier(std::string &textTrackIdentifier) 
 * @brief Get Text Track Identifier
 *
 * @param[in] textTrackIdentifier Text track identifier of subtitle stream
 *
 * @retval true on success false otherwise
 */
message GetTextTrackIdentifierRequest {
    optional int32 session_id = 1 [default = -1];
}
message GetTextTrackIdentifierResponse {
    optional string text_track_identifier = 1;
}

/**
 * @fn void setLowLatency(bool lowLatency)
 * @brief Set low latency property on the pipeline.
 *
 * @param[in] lowLatency : The low latency value to set.
 *
 */
message SetLowLatencyRequest {
    optional int32 session_id = 1 [default = -1];
    optional bool low_latency = 2;
}
message SetLowLatencyResponse {
}

/**
 * @fn void setSync(bool sync)
 * @brief Set sync property on the pipeline.
 *
 * @param[in] session_id  The id of the A/V session the request is for.
 * @param[in] sync        The sync value to set.
 *
 */
message SetSyncRequest {
    optional int32 session_id = 1 [default = -1];
    optional bool sync = 2;
}
message SetSyncResponse {
}

/**
 * @fn void getSync(bool &sync)
 * @brief Get sync property on the pipeline.
 *
 * @param[in]  session_id  The id of the A/V session the request is for.
 * @param[out] sync        Current sync value.
 *
 * @retval true on success false otherwise
 */
message GetSyncRequest {
    optional int32 session_id = 1 [default = -1];
}
message GetSyncResponse {
    optional bool sync = 1;
}

/**
 * @fn void setSyncOff(bool sync_off)
 * @brief Set sync off property on the pipeline.
 *
 * @param[in] session_id  The id of the A/V session the request is for.
 * @param[in] sync_off    The sync off value to set.
 *
 */
message SetSyncOffRequest {
    optional int32 session_id = 1 [default = -1];
    optional bool sync_off = 2;
}
message SetSyncOffResponse {
}

/**
 * @fn void setStreamSyncMode(int32 stream_sync_mode)
 * @brief Set stream sync mode property on the pipeline.
 *
 * @param[in] session_id        The id of the A/V session the request is for.
 * @param[in] stream_sync_mode  The stream sync mode value to set.
 * @param[in] sourceId          The source id. Value should be set to the MediaSource.id returned after attachSource()
 *
 */
message SetStreamSyncModeRequest {
    optional int32 session_id = 1 [default = -1];
    optional int32 stream_sync_mode = 2;
    optional int32 source_id = 3 [default = -1];
}
message SetStreamSyncModeResponse {
}

/**
 * @fn void getStreamSyncMode(int32 &stream_sync_mode)
 * @brief Get stream sync mode property on the pipeline.
 *
 * @param[in]  session_id       The id of the A/V session the request is for.
 * @param[out] stream_sync_mode Current stream sync mode value.
 *
 * @retval true on success false otherwise
 */
message GetStreamSyncModeRequest {
    optional int32 session_id = 1 [default = -1];
}
message GetStreamSyncModeResponse {
    optional int32 stream_sync_mode = 1;
}

/**
 * @fn void flush(int session_id, int source_id)
 * @brief Flush a media source for a session.
 *
 * @param[in]  session_id   The id of the A/V session.
 * @param[in]  source_id    The id of the media source to flush.
 * @param[in]  reset_time   True if time should be reset
 *
 */
message FlushRequest {
  optional int32 session_id = 1 [default = -1];
  optional int32 source_id = 2 [default = -1];
  optional bool reset_time = 3 [default = false];
}
message FlushResponse {
}

/**
 * @fn void setSourcePosition(int session_id, int source_id, int64 position)
 * @brief Set the source position in nanoseconds.
 *
 * @param[in]  session_id   The id of the A/V session.
 * @param[in]  source_id    The id of the media source.
 * @param[in]  position     The position in nanoseconds.
 * @param[in]  reset_time   True if time should be reset
 * @param[in]  applied_rate The applied rate after seek
 *
 * This method sets the start position for a source.
 *
 */
message SetSourcePositionRequest {
    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
    optional int64 position = 3 [default = -1];
    optional bool reset_time = 4 [default = false];
    optional double applied_rate = 5 [default = 1];
}
message SetSourcePositionResponse {
}

/**
 * @fn void setImmediateOutput(int session_id, int source_id, bool immediate_output)
 * @brief Sets the "Immediate Output" property for this source.
 *
 * @param[in]  session_id        The id of the A/V session.
 * @param[in]  source_id         The id of the media source.
 * @param[in]  immediate_output  Set immediate output mode on the sink
 *
 */
message SetImmediateOutputRequest {
    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
    optional bool immediate_output = 3 [default = false];
}
message SetImmediateOutputResponse {
}

/**
 * @fn void getImmediateOutput(int session_id, int source_id, bool &immediate_output)
 * @brief Gets the "Immediate Output" property for this source.
 *
 * @param[in]  session_id        The id of the A/V session.
 * @param[in]  source_id         The id of the media source.
 * @param[out] immediate_output  Get immediate output mode on the sink
 *
 */
message GetImmediateOutputRequest {
    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
}
message GetImmediateOutputResponse {
    optional bool immediate_output = 1 [default = false];
}

/**
 * @fn void getStats(int session_id, int source_id, uint64 &rendered_frames, uint64 &dropped_frames)
 * @brief Get various stats from the source.
 *
 * @param[in]  session_id        The id of the A/V session.
 * @param[in]  source_id         The id of the media source.
 * @param[out] rendered_frames   The number of rendered frames
 * @param[out] dropped_frames    The number of dropped frames
 *
 * This method gets various stats from the source.
 *
 */
message GetStatsRequest {
    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
}
message GetStatsResponse {
    optional int64 rendered_frames = 1 [default = -1];
    optional int64 dropped_frames = 2 [default = -1];
}

/**
 * @fn void processAudioGap(int64 position, uint32 duration, uint32 level)
 * @brief Process audio gap.
 *
 * @param[in] session_id        The id of the A/V session.
 * @param[in] position          Audio pts fade pts value
 * @param[in] duration          Audio pts fade duration
 * @param[in] discontinuity_gap Audio discontinuity gap
 * @param[in] audio_aac         True if audio codec is AAC
 *
 * This method handles audio gap in order to avoid audio pops during transitions.
 *
 */
message ProcessAudioGapRequest {
    optional int32 session_id = 1 [default = -1];
    optional int64 position = 2 [default = -1];
    optional uint32 duration = 3 [default = 0];
    optional int64 discontinuity_gap = 4 [default = 0];
    optional bool audio_aac = 5 [default = false];
}
message ProcessAudioGapResponse {
}

/**
 * @fn void setBufferingLimit(uint32_t limitBufferingMs)
 * @brief Set buffering limit
 *
 * @param[in] session_id        The id of the A/V session.
 * @param[in] limitBufferingMs  buffering limit in ms
 *
 * This method sets millisecond threshold used if limit_buffering is set.
 * Changing this value does not enable/disable limit_buffering
 *
 */
message SetBufferingLimitRequest {
    optional int32 session_id = 1 [default = -1];
    optional uint32 limit_buffering_ms = 2 [default = 0];
}
message SetBufferingLimitResponse {
}

/**
 * @fn void getBufferingLimit(uint32_t &limitBufferingMs)
 * @brief Get buffering limit
 *
 * @param[in] session_id        The id of the A/V session.
 * @param[out] limitBufferingMs buffering limit in ms
 *
 * This method returns current value of buffering limit in milliseconds
 * Method will return kInvalidLimitBuffering limit buffering is disabled
 *
 */
message GetBufferingLimitRequest {
    optional int32 session_id = 1 [default = -1];
}
message GetBufferingLimitResponse {
    optional uint32 limit_buffering_ms = 1 [default = 0];
}

/**
 * @fn void setUseBuffering(bool useBuffering)
 * @brief Enables/disables the buffering option
 *
 * @param[in] session_id        The id of the A/V session.
 * @param[in] useBuffering      true if buffering option enabled.
 *
 * This method enables the buffering option so that BUFFERING messages are
 * emitted based on low-/high-percent thresholds.
 *
 */
message SetUseBufferingRequest {
    optional int32 session_id = 1 [default = -1];
    optional bool use_buffering = 2 [default = false];
}
message SetUseBufferingResponse {
}

/**
 * @fn void bool getBufferingLimit(uint32_t &limitBufferingMs)
 * @brief Checks, if buffering is enabled
 *
 * @param[in] session_id        The id of the A/V session.
 * @param[out] useBuffering     true if buffering option enabled.
 *
 * This method returns true, if buffering is enabled
 *
 */
message GetUseBufferingRequest {
    optional int32 session_id = 1 [default = -1];
}
message GetUseBufferingResponse {
    optional bool use_buffering = 1 [default = false];
}

/**
 * @brief Event sent the playback state has changed.
 *
 * @param session_id   The id of the A/V session the status is for.
 * @param state        The new state of the playback session.
 *
 */
message PlaybackStateChangeEvent {

    enum PlaybackState {
        UNKNOWN = 0;        ///< An unknown or undefined playback state.
        IDLE = 1;           ///< The backend player is idle.
        PLAYING = 2;        ///< The backend player is playing media.
        PAUSED = 3;         ///< The backend player is paused.
        SEEKING = 4;        ///< The backend player is seeking a new playback position.
        SEEK_DONE = 5;      ///< The backend player has finished seek.
        STOPPED = 6;        ///< The backend player has stopped playback.
        END_OF_STREAM = 7;  ///< The backend player has got to the end of playback.
        FAILURE = 8;        ///< The backend player failed to set playback state.
    }

    optional int32 session_id = 1 [default = -1];
    optional PlaybackState state = 2;
}

/**
 * @brief Event sent the network state has changed.
 *
 * @param session_id   The id of the A/V session the status is for.
 * @param state        The new state of the network session.
 *
 */
message NetworkStateChangeEvent {

    enum NetworkState {
        UNKNOWN = 0;            ///< An unknown or undefined network state.
        IDLE = 1;               ///< The network is idle.
        BUFFERING = 2;          ///< The network is buffering data before playing.
        BUFFERING_PROGRESS = 3; ///< The network is buffering data whilst playing.
        BUFFERED = 4;           ///< All the data is buffered.
        STALLED = 5;            ///< The network has stalled but may recover.
        FORMAT_ERROR = 6;       ///< The data is the wrong format.
        NETWORK_ERROR = 7;      ///< There has been a network error. Playback stops.
        DECODE_ERROR = 8;       ///< There has been a decode error of the data.
    }

    optional int32 session_id = 1 [default = -1];
    optional NetworkState state = 2;
}

/**
 * @brief Event sent the position has changed.
 *
 * @param session_id   The id of the A/V session the status is for.
 * @param position     The position in nanoseconds
 *
 */
message PositionChangeEvent {
    optional int32 session_id = 1 [default = -1];
    optional int64 position = 2 [default = -1];
}

/**
 * @brief Event sent by the server when data is needed for a media source.
 *
 * @param session_id        The id of the A/V session the request is for.
 * @param source_id         The id of the media source the request is for.
 * @param request_id        The id of the request.
 * @param frame_count       The number of frames to read.
 * @param shm_info          Information for populating the shared memory (nullptr if not applicable to the client).
 *
 * This is sent by the server whenever data is needed for a given media source.  The client is expected to respond with
 * a haveData() call, referencing the NeedMediaDataEvent that triggered it.
 */
message NeedMediaDataEvent {

    message MediaPlayerShmInfo {
        optional uint32 max_metadata_bytes = 1;
        optional uint32 metadata_offset = 2;
        optional uint32 media_data_offset = 3;
        optional uint32 max_media_bytes = 4;
    }

    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
    optional uint32 request_id = 3;

    optional uint32 frame_count = 4;
    optional MediaPlayerShmInfo shm_info = 5;
}

/**
 * @brief Event sent by the server when a QOS message has been raised.
 *
 * @param session_id        The id of the A/V session the request is for.
 * @param source_id         The id of the media source the request is for.
 * @param qos_info          Information from the QOS message.
 *
 * This is sent by the server whenever frames are dropped from a buffer.
 */
message QosEvent {

    message QosInfo {
        optional uint64 processed = 1;
        optional uint64 dropped = 2;
    }

    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
    optional QosInfo qos_info = 3;
}

/**
 * @brief Event sent by the server when a buffer underflow has been raised.
 *
 * @param session_id        The id of the A/V session the request is for.
 * @param source_id         The id of the media source the request is for.
 *
 * This is sent by the server whenever buffer underflow occurs
 */
message BufferUnderflowEvent {
    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
}

/**
 * @brief Event sent by the server when a non-fatal error has occurred in the player.
 *
 * @param session_id        The id of the A/V session the request is for.
 * @param source_id         The id of the media source the request is for.
 * @param error             The type of error that occurred.
 */
message PlaybackErrorEvent {
    enum PlaybackError {
        UNKNOWN = 0;            ///< An unknown or undefined network state.
        DECRYPTION = 1;         ///< Player failed to decrypt a buffer and the frame has been dropped.
    }

    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
    optional PlaybackError error = 3;
}

/**
 * @brief Requests RialtoClient to change its log levels
 *
 * @param[in]  defaultLogLevels       Desired default log level
 * @param[in]  clientLogLevels        Desired client log level
 * @param[in]  ipcLogLevels           Desired ipc log level
 * @param[in]  commonLogLevels        Desired ipc log level
 *
 */
message SetLogLevelsEvent {
    optional uint32 defaultLogLevels = 1;
    optional uint32 clientLogLevels = 2;
    optional uint32 ipcLogLevels = 3;
    optional uint32 commonLogLevels = 4;
}

/**
 * @brief Event sent by the server when a source has been flushed.
 *
 * @param session_id        The id of the A/V session the request is for.
 * @param source_id         The id of the media source the request is for.
 */
message SourceFlushedEvent {
    optional int32 session_id = 1 [default = -1];
    optional int32 source_id = 2 [default = -1];
}

service MediaPipelineModule {
    /**
     * @brief Creates a new playback session.
     * @see CreateSessionRequest
     */
    rpc createSession(CreateSessionRequest) returns (CreateSessionResponse) {
    }

    /**
     * @brief Destroys a playback session.
     * @see DestroySessionRequest
     */
    rpc destroySession(DestroySessionRequest) returns (DestroySessionResponse) {
    }

    /**
     * @brief Loads the media pipeline.
     * @see LoadRequest
     */
    rpc load(LoadRequest) returns (LoadResponse) {
    }

    /**
     * @brief Attach a new audio or video media source.
     * @see AttachSourceRequest
     */
    rpc attachSource(AttachSourceRequest) returns (AttachSourceResponse) {
    }

    /**
     * @brief Remove the media source.
     * @see RemoveSourceRequest
     */
    rpc removeSource(RemoveSourceRequest) returns (RemoveSourceResponse) {
    }

    /**
     * @brief Notify that all sources were attached
     * @see AllSourcesAttachedRequest
     */
    rpc allSourcesAttached(AllSourcesAttachedRequest) returns (AllSourcesAttachedResponse) {
    }

    /**
     * @brief Sets the on-screen dimensions of the video window.
     * @see SetVideoWindowRequest
     */
    rpc setVideoWindow(SetVideoWindowRequest) returns (SetVideoWindowResponse) {
    }

    /**
     * @brief Starts/resumes the playback.
     * @see PlayRequest
     */
    rpc play(PlayRequest) returns (PlayResponse) {
    }

    /**
     * @brief Pauses the playback.
     * @see PauseRequest
     */
    rpc pause(PauseRequest) returns (PauseResponse) {
    }

    /**
     * @brief Stops playback.
     * @see StopRequest
     */
    rpc stop(StopRequest) returns (StopResponse) {
    }

    /**
     * @brief Sets the position of the playback (seek)
     * @see SetPositionRequest
     */
    rpc setPosition(SetPositionRequest) returns (SetPositionResponse) {
    }

    /**
     * @brief Gets the current position of the playback
     * @see GetPositionRequest
     */
    rpc getPosition(GetPositionRequest) returns (GetPositionResponse) {
    }

    /**
     * @brief Sets the "Immediate Output" property for this source.
     * @see SetImmediateOutputRequest
     */
    rpc setImmediateOutput(SetImmediateOutputRequest) returns (SetImmediateOutputResponse) {
    }

    /**
     * @brief Gets the "Immediate Output" property for this source.
     * @see GetImmediateOutputRequest
     */
    rpc getImmediateOutput(GetImmediateOutputRequest) returns (GetImmediateOutputResponse) {
    }

    /**
     * @brief Gets the current stats property
     * @see GetStatsRequest
     */
    rpc getStats(GetStatsRequest) returns (GetStatsResponse) {
    }

    /**
     * @brief Sets the playback rate
     * @see SetPlaybackRateRequest
     */
    rpc setPlaybackRate(SetPlaybackRateRequest) returns (SetPlaybackRateResponse) {
    }

    /**
     * @brief Indicates that the data is ready to be consumed in response to a NeedMediaDataEvent.
     * @see HaveDataRequest
     */
    rpc haveData(HaveDataRequest) returns (HaveDataResponse) {
    }

    /**
     * @brief Requests to render a prerolled frame
     * @see RenderFrameRequest
     */
    rpc renderFrame(RenderFrameRequest) returns (RenderFrameResponse) {
    }

    /**
     * @brief Set the target volume level and transition duration with easing type
     * @see SetVolumeRequest
     */
    rpc setVolume(SetVolumeRequest) returns (SetVolumeResponse) {
    } 

    /**
     * @brief Get current audio level. Fetches the current volume level for the pipeline.
     * @see GetVolumeRequest
     */
    rpc getVolume(GetVolumeRequest) returns (GetVolumeResponse) {
    }

    /**
     * @brief Set mute status of pipeline.
     * @see SetMuteRequest
     */
    rpc setMute(SetMuteRequest) returns (SetMuteResponse) {
    } 

    /**
     * @brief Get current mute status of the pipeline
     * @see GetMuteRequest
     */
    rpc getMute(GetMuteRequest) returns (GetMuteResponse) {
    }

    /**
     * @brief Text Track Identifier
     * @see SetTextTrackIdentifierRequest
     */
    rpc setTextTrackIdentifier(SetTextTrackIdentifierRequest) returns (SetTextTrackIdentifierResponse) {
    } 

    /**
     * @brief Get Text Track Identifier
     * @see GetTextTrackIdentifierRequest
     */
    rpc getTextTrackIdentifier(GetTextTrackIdentifierRequest) returns (GetTextTrackIdentifierResponse) {
    }

    /**
     * @brief Set low latency property on the pipeline.
     * @see SetLowLatencyRequest
     */
    rpc setLowLatency(SetLowLatencyRequest) returns (SetLowLatencyResponse) {
    } 

    /**
     * @brief Set sync property on the pipeline.
     * @see SetSyncRequest
     */
    rpc setSync(SetSyncRequest) returns (SetSyncResponse) {
    } 

    /**
     * @brief Get sync property on the pipeline.
     * @see GetSyncRequest
     */
    rpc getSync(GetSyncRequest) returns (GetSyncResponse) {
    } 

    /**
     * @brief Set sync off property on the pipeline.
     * @see SetSyncOffRequest
     */
    rpc setSyncOff(SetSyncOffRequest) returns (SetSyncOffResponse) {
    } 

    /**
     * @brief Set stream sync mode property on the pipeline.
     * @see SetStreamSyncModeRequest
     */
    rpc setStreamSyncMode(SetStreamSyncModeRequest) returns (SetStreamSyncModeResponse) {
    } 

    /**
     * @brief Get stream sync mode property on the pipeline.
     * @see GetStreamSyncModeRequest
     */
    rpc getStreamSyncMode(GetStreamSyncModeRequest) returns (GetStreamSyncModeResponse) {
    } 

    /**
     * @brief Flush the media source.
     * @see FlushRequest
     */
    rpc flush(FlushRequest) returns (FlushResponse) {
    }

    /**
     * @brief This method sets the start position for a source.
     * @see SetSourcePositionRequest
     */
    rpc setSourcePosition(SetSourcePositionRequest) returns (SetSourcePositionResponse) {
    }

    /**
     * @brief This method handles audio gap in order to avoid audio pops during transitions.
     * @see ProcessAudioGapRequest
     */
    rpc processAudioGap(ProcessAudioGapRequest) returns (ProcessAudioGapResponse) {
    }

    /**
     * @brief This method sets millisecond threshold used if limit_buffering is set.
     * @see SetBufferingLimitRequest
     */
    rpc setBufferingLimit(SetBufferingLimitRequest) returns (SetBufferingLimitResponse) {
    }

    /**
     * @brief Get buffering limit
     * @see GetBufferingLimitRequest
     */
    rpc getBufferingLimit(GetBufferingLimitRequest) returns (GetBufferingLimitResponse) {
    }

    /**
     * @brief This method enables the buffering option so that BUFFERING messages are
     *        emitted based on low-/high-percent thresholds.
     * @see SetUseBufferingRequest
     */
    rpc setUseBuffering(SetUseBufferingRequest) returns (SetUseBufferingResponse) {
    }

    /**
     * @brief Checks, if buffering is enabled
     * @see GetUseBufferingRequest
     */
    rpc getUseBuffering(GetUseBufferingRequest) returns (GetUseBufferingResponse) {
    }
}
